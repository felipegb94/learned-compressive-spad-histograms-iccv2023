hydra: 
  run:
    # Configure output dir of each experiment programmatically from the arguments
    # Example "outputs/mnist/classifier/baseline/2021-03-10-141516"
    # dir: outputs/${data.name}/${model.name}/${experiment}/${now:%Y-%m-%d_%H%M%S}
    # dir: outputs/${dataset.name}/${.model_name}/${experiment}/${experiment_id}
    dir: ${model_dirpath}

defaults:
  - io_dirpaths
  - _self_
  - dataset: middlebury
  # enable color logging
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog

train_dataset: nyuv2_64x64x1024_80ps

## Peng et al., 2020 --> Full trained model NO gradient decay
# model_dirpath: outputs/${.model_name}/debug_nyuv2/2022-04-19_205134

# ## Peng et al., 2020 --> Full trained model with gradient decay
# model_name: DDFN_C64B10_NL_original
# model_dirpath: outputs/${.train_dataset}/debug/${.model_name}/debug/2022-04-20_185832
# ckpt_id: epoch=05-step=19910-avgvalrmse=0.0281

# ## Peng et al., 2020 (Plain Deep Boosting w/out NL) --> Full trained model with gradient decay
# model_name: DDFN_C64B10
# model_dirpath: outputs/${.train_dataset}/DDFN_C64B10/debug/2022-04-25_192521
# ckpt_id: epoch=05-step=19910-avgvalrmse=0.0287

# ## Non-Local Depth2Depth Model --> Full trained model with gradient decay
# model_name: DDFN_C64B10_NL_Depth2Depth
# model_dirpath: outputs/${.train_dataset}/debug/${.model_name}/debug/2022-04-22_134732
# ckpt_id: epoch=05-step=19045-avgvalrmse=0.0363

# ## Compressive --> Full trained model with gradient decay
# model_name: DDFN_C64B10_NL_Compressive
# model_dirpath: outputs/${.train_dataset}/debug/${.model_name}/debug/2022-04-23_132059
# ckpt_id: epoch=06-step=23373-avgvalrmse=0.0320

# ## CompressiveWithBias --> Full trained model with gradient decay
# model_name: DDFN_C64B10_NL_CompressiveWithBias
# model_dirpath: outputs/${.train_dataset}/debug/${.model_name}/debug/2022-04-24_142932
# ckpt_id: epoch=05-step=18180-avgvalrmse=0.0323


# ## Depth2Depth Model --> Full trained model with gradient decay
# model_name: DDFN2D_Depth2Depth/B-12_MS-8
# model_dirpath: outputs/${.train_dataset}/debug/${.model_name}/debug/2022-04-27_103314
# ckpt_id: epoch=29-step=103022-avgvalrmse=0.0306 # use last one

## Depth2Depth Model --> Full trained model with gradient decay
model_name: DDFN2D_Depth2Depth_01Inputs/B-12_MS-8
model_dirpath: outputs/${.train_dataset}/debug/${.model_name}/debug/2022-04-27_104532
ckpt_id: epoch=29-step=101292-avgvalrmse=0.0280 # use last one


# ckpt_id: epoch=04-step=400-avgvalrmse=0.0700
# ckpt_id: null
## Compressive

params:
  gpu_num: 1
  cuda: true
  batch_size: 1
  # model_name: DDFN_C64B10_NL
  noise_idx: null
  test_datalist_fpath: ${io_dirpaths.datalists_dirpath}/${dataset.test_datalist_fname}


