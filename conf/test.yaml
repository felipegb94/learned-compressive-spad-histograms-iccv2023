hydra: 
  run:
    # Configure output dir of each experiment programmatically from the arguments
    # Example "outputs/mnist/classifier/baseline/2021-03-10-141516"
    # dir: outputs/${data.name}/${model.name}/${experiment}/${now:%Y-%m-%d_%H%M%S}
    # dir: outputs/${dataset.name}/${.model_name}/${experiment}/${experiment_id}
    dir: ${model_dirpath}
  sweep:
    dir: ${model_dirpath}
    subdir: ./

defaults:
  - io_dirpaths
  - _self_
  - dataset: middlebury
  # - dataset: lindell2018_linospad
  # - dataset: lindell2018_linospad_patches
  # - dataset: lindell2018_linospad_min
  # - dataset: nyuv2_min
  # - dataset: nyuv2
  # enable color logging
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog

train_dataset: nyuv2_64x64x1024_80ps

# Emulate int8 quantization on csph3d_layer weights?
emulate_int8_quantization: false

##########################################
## Peng et al., 2020 Baselines and Modified 
# ## Peng et al., 2020 (Plain Deep Boosting w/out NL) --> Full trained model with gradient decay
# model_name: DDFN_C64B10/loss-kldiv_tv-1e-5
# experiment_name: baselines
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/2022-04-25_192521
# ckpt_id: epoch=05-step=19910-avgvalrmse=0.0287 # 0.0180 | 0.0177 | 0.0203 | 128 images == 0.0314

##########################################
## 1D CSPH with ZNCC Upsampling
#### K = 8 (compression = 128x)
# ## K=8 HybridGrayFourier 3D DB Plain CSPH1D Model (No TV | LR=1e-3) --> Full trained model with gradient decay
# model_name: DDFN_C64B10_CSPH1D/k8_HybridGrayFourier/loss-kldiv_tv-0.0
# experiment_name: baselines_csph1d
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/2022-05-27_181604
# ckpt_id: epoch=19-step=67528-avgvalrmse=0.0201 # 0.0442 | 0.0320 | 
#### K = 32 (compression = 32x)
# ## K=32 HybridGrayFourier 3D DB Plain CSPH1D Model (No TV | LR=1e-3) --> Full trained model with gradient decay
# model_name: DDFN_C64B10_CSPH1D/k32_HybridGrayFourier/loss-kldiv_tv-0.0
# experiment_name: baselines_csph1d
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/2022-05-20_194601
# ckpt_id: epoch=19-step=69259-avgvalrmse=0.0152 # 0.0208 | 
#### K = 64 (compression = 16x)
# ## K=64 CoarseHist 3D DB Plain CSPH1D Model (No TV) --> Full trained model with gradient decay
# model_name: DDFN_C64B10_CSPH1D/k64_CoarseHist/loss-kldiv_tv-0.0
# experiment_name: baselines_csph1d
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/2022-05-17_224020
# ckpt_id: epoch=09-step=32898-avgvalrmse=0.0198 # ~0.0413

##########################################
## 3D CSPH with Pseudo-inverse Upsampling
##  Debugging generalization

# ## 16x compression codes=(1024x1x1) tblock_init=TruncFourier K=64 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k64_down1_Mt1_TruncFourier-optCt=False-optC=False_csph1d_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-latest_2022-08-27_180922
# ckpt_id: epoch=09-step=32898-avgvalrmse=0.0170.ckpt # 0.0172 | 120 images== | 128 images==0.0164

# ## 32x compression codes=(1024x1x1) tblock_init=TruncFourier K=32 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k32_down1_Mt1_TruncFourier-optCt=False-optC=False_csph1d_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-complete_2022-08-29_164722
# ckpt_id: epoch=26-step=93500-avgvalrmse=0.0151.ckpt # 0.0204 | 120 images== | 128 images==0.0218

# ## 32x compression codes=(1024x1x1) tblock_init=BindaryRand K=32 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k32_down1_Mt1_BinaryRand-optCt=False-optC=False_csph1d_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-complete_2022-08-28_032306
# ckpt_id: epoch=29-step=102158-avgvalrmse=0.0274.ckpt # 0.292 | 120 images== | 128 images==01.05

# ## 64x compression codes=(1024x1x1) tblock_init=HybridGrayFourier K=16 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k16_down1_Mt1_HybridGrayFourier-optCt=False-optC=False_csph1d_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-latest_2022-08-29_214704
# ckpt_id: epoch=09-step=32898-avgvalrmse=0.0205.ckpt # 0.0364 | 120 images== | 128 images==0.0378

# ## 32x compression codes=(1024x4x4) tblock_init=TruncFourier K=512 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k512_down4_Mt1_TruncFourier-optCt=True-optC=True_full_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-complete_2022-08-29_164722
# ckpt_id: epoch=20-step=72722-avgvalrmse=0.0179.ckpt # 0.0230 | 120 images== | 128 images==0.0414

# ## 32x compression separable codes=(1024x4x4) tblock_init=TruncFourier K=512 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k512_down4_Mt1_TruncFourier-optCt=True-optC=True_separable_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-complete_2022-08-29_164722
# ckpt_id: epoch=28-step=98695-avgvalrmse=0.0168.ckpt #  0.0198 | 120 images== | 128 images==0.0304

# ## 32x compression separable codes=(1024x4x4) tblock_init=HybridGrayFourier K=512 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k512_down4_Mt1_HybridGrayFourier-optCt=False-optC=True_separable_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-complete_2022-08-29_195412
# ckpt_id: epoch=28-step=98695-avgvalrmse=0.0177.ckpt # 0.0214 | 120 images== | 128 images==0.0234

# ## 128x compression  codes=(1024x4x4) tblock_init=HybridGrayFourier K=128 norm=LinfGlobal
# model_name: DDFN_C64B10_CSPH3Dv2/k128_down4_Mt1_HybridGrayFourier-optCt=False-optC=True_separable_norm-LinfGlobal/loss-kldiv_tv-0.0
# experiment_name: csph3d_debug_generalization
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-complete_2022-08-29_195412
# ckpt_id: epoch=29-step=102158-avgvalrmse=0.0193.ckpt #  0.0229 | 120 images== | 128 images==0.0225

##########################################
## 3D CSPH with Pseudo-inverse Upsampling

##### codes=(1024x4x4) tblock_init=Rand encoding_type=full

# ## 32x compression (K=512 1024x4x4)
# model_name: DDFN_C64B10_CSPH3Dv2/k512_down4_Mt1_Rand-optCt=True-optC=True_full_norm-none/loss-kldiv_tv-0.0
# experiment_name: csph3d_good_norm
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/run-complete_2022-08-10_162141
# ckpt_id: epoch=28-step=98695-avgvalrmse=0.0171 # 0.0191 | 120 images==0.3567 | 128 images==0.395

# ## 128x compression (K=128 1024x4x4)
# model_name: DDFN_C64B10_CSPH3Dv1/k128_down4_Mt1_Rand-optCt=True-optC=True_full/loss-kldiv_tv-0.0
# experiment_name: test_csph3d
# model_dirpath: outputs/${.train_dataset}/${.experiment_name}/${.model_name}/2022-07-31_145411
# ckpt_id: epoch=26-step=91769-avgvalrmse=0.0180 # 0.0240 | 120 images==0.177 | 128 images==0.169

params:
  gpu_num: 1
  batch_size: 1
  num_workers: 0
  cuda: true
  noise_idx: null
  test_datalist_fpath: ${io_dirpaths.datalists_dirpath}/${dataset.test_datalist_fname}


